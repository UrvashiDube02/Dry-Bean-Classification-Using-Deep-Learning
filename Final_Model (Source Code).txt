# -*- coding: utf-8 -*-
"""
Created on Thu Aug  3 13:32:02 2023

@author: urvas
"""

###############################################################################

# Importing libraries
import tensorflow as tf
from keras.layers import Input, Dense, Flatten, BatchNormalization
from tensorflow import keras
from tensorflow.keras.models import save_model
from tensorflow.keras.utils import plot_model
from tensorflow.keras.applications import ResNet50

import warnings # to ignore future warnings
warnings.filterwarnings("ignore", category = FutureWarning)

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns

###############################################################################

# Dataset Path
data_dir = "C:/Users/urvas/Projects/Dry Beans Classification Projects/Dry_Bean_Image_Dataset/Original Dataset 256"
  
###############################################################################

# Setting dimensions of image and batch size 
img_height, img_width = 256, 256
batch_size = 32

###############################################################################

# Splitting into training and validation parts
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)

class_names = train_ds.class_names
print(class_names)

###############################################################################

# Calculate the number of classes
num_classes = len(train_ds.class_names)

###############################################################################

# One-hot encode the labels for train_ds and val_ds
def one_hot_encode_labels(images, labels):
    labels = tf.one_hot(labels, depth=num_classes)
    return images, labels

train_ds = train_ds.map(one_hot_encode_labels)
val_ds = val_ds.map(one_hot_encode_labels)

###############################################################################

# Creating the model

# Input Shape
input_shape = (256, 256, 3)

# Creating the input layer
input_layer = Input(shape=input_shape, name='input_4')

resnet_base = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)

# Freeze weights of the pre-trained layers
for layer in resnet_base.layers:
    layer.trainable = False

# Add custom layers on top of ResNet50
x = resnet_base.output

# Flatten
flatten_layer = Flatten(name='flatten_3')(x)

# Dense layers
dense1 = Dense(256, activation='relu', name='dense_9')(flatten_layer)
batch_norm1 = BatchNormalization(name='batch_normalization_6')(dense1)

output_layer = Dense(14, activation='softmax', name='dense_11')(batch_norm1)

# Creating model
model = tf.keras.models.Model(inputs = input_layer, outputs=output_layer)

# Printing summary of the model
model.summary()

###############################################################################

# Compiling the model
model.compile(
    optimizer=keras.optimizers.Adam(1e-3),
    loss="categorical_crossentropy",
    metrics=["accuracy"],)

###############################################################################

mse_values = []

class MSECallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        mse_values.append(logs['loss'])

model.fit(
    train_ds,
    epochs=5,
    validation_data=val_ds,
    steps_per_epoch=350,
    callbacks=[MSECallback()],
    verbose=1
)

###############################################################################

"""
# Saving the summary of  the model in a text file

from contextlib import redirect_stdout
def save_model_summary_to_txt(model, file_path):
    with open(file_path, 'w') as f:
        with redirect_stdout(f):
            model.summary()

save_model_summary_to_txt(model, 'Final_model.txt')

"""
###############################################################################

# Saving model
save_model(model, 'C:/Users/urvas/Projects/Dry Beans Classification Projects/Programs Used/Models/My_Model_4.h5');

###############################################################################
# Plotting model
plot_model(model, to_file='C:/Users/urvas/Projects/Dry Beans Classification Projects/Programs Used/Models/My_Model_4.png', show_shapes=True);

###############################################################################

# Plotting graph of MSE versus iteration
plt.plot(np.arange(1, len(mse_values) + 1), mse_values, marker='o')
plt.xlabel('Iteration')
plt.ylabel('Mean Squared Error')
plt.title('Mean Squared Error vs. Iteration')
plt.grid(True)
plt.show()

###############################################################################

val_labels = np.concatenate([y for x, y in val_ds], axis=0)
val_predictions = model.predict(val_ds)
val_predictions = np.argmax(val_predictions, axis=1)

# Converting val_labels from one-hot to single-dimensional format
val_labels_single = np.argmax(val_labels, axis=1)

# Generating confusion matrix
cm = confusion_matrix(val_labels_single, val_predictions)

# Plotting confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(14), yticklabels=range(14))
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

###############################################################################